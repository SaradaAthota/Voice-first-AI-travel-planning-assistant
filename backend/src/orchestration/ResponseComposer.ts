/**
 * ResponseComposer
 * 
 * Composes natural language responses from tool outputs and context.
 * 
 * Responsibilities:
 * - Generate user-facing responses using LLM
 * - Incorporate tool outputs into responses
 * - Include citations from RAG sources
 * - Maintain conversational tone
 * 
 * Rules:
 * - LLM is used HERE for response generation (not tool calling)
 * - Responses must include citations when available
 * - Responses should be concise for voice (TTS)
 * - Citations appear in UI, not in voice response
 */

import OpenAI from 'openai';
import {
  ConversationContext,
  ToolCallResult,
  ComposedResponse,
  Citation,
} from './types';
import { config } from '../config/env';

export class ResponseComposer {
  private openai: OpenAI;

  constructor() {
    if (!config.openai?.apiKey) {
      throw new Error('OpenAI API key is required for ResponseComposer');
    }
    this.openai = new OpenAI({ apiKey: config.openai.apiKey });
  }

  /**
   * Compose response based on context and tool results
   * 
   * This is where LLM generates the actual user-facing text.
   * Tool outputs are provided as context, not generated by LLM.
   */
  async composeResponse(
    context: ConversationContext,
    toolCalls: ToolCallResult[],
    userMessage?: string
  ): Promise<ComposedResponse> {
    // Collect all citations from tool outputs
    const citations: Citation[] = [];
    for (const call of toolCalls) {
      if (call.output.citations) {
        citations.push(...call.output.citations);
      }
    }

    // Build prompt based on state
    const systemPrompt = this.buildSystemPrompt(context);
    const userPrompt = this.buildUserPrompt(context, toolCalls, userMessage);

    try {
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4-turbo-preview',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt },
        ],
        temperature: 0.7, // Higher temperature for more natural responses
      });

      const text = response.choices[0]?.message?.content || 'I apologize, I encountered an error.';

      return {
        text: this.optimizeForVoice(text),
        citations: citations.length > 0 ? citations : undefined,
        state: context.state,
        metadata: {
          tripId: context.tripId,
        },
      };
    } catch (error) {
      console.error('Response composition error:', error);
      return this.fallbackResponse(context, toolCalls);
    }
  }

  /**
   * Build system prompt for response generation
   */
  private buildSystemPrompt(context: ConversationContext): string {
    const basePrompt = `You are a helpful voice-first travel planning assistant.
Your responses will be converted to speech, so keep them:
- Concise and natural
- Conversational and friendly
- Clear and easy to understand when spoken

Current conversation state: ${context.state}

Rules:
- Never mention that you're using tools or databases
- If data is missing, say so explicitly (e.g., "I don't have information about...")
- Be specific about recommendations
- For explanations, cite sources naturally`;

    switch (context.state) {
      case 'INIT':
        return `${basePrompt}
You're starting a new conversation. Greet the user and ask about their trip.`;

      case 'COLLECTING_PREFS':
        return `${basePrompt}
You're collecting trip preferences. Ask clarifying questions naturally.
Collected so far: ${context.collectedFields.join(', ')}
Still need: ${context.missingFields.join(', ')}`;

      case 'CONFIRMING':
        return `${basePrompt}
You're confirming the trip details before generating the itinerary.
Summarize what you understand and ask for confirmation.`;

      case 'PLANNED':
        return `${basePrompt}
An itinerary has been generated. You can:
- Present the itinerary
- Answer questions about it
- Help with edits`;

      case 'EDITING':
        return `${basePrompt}
The user is editing the itinerary. Acknowledge the edit and confirm what changed.`;

      case 'EXPLAINING':
        return `${basePrompt}
The user is asking for explanations. Provide clear, grounded explanations.
If you cite sources, mention them naturally (e.g., "According to Wikivoyage...").`;

      default:
        return basePrompt;
    }
  }

  /**
   * Build user prompt with context and tool outputs
   */
  private buildUserPrompt(
    context: ConversationContext,
    toolCalls: ToolCallResult[],
    userMessage?: string
  ): string {
    let prompt = '';

    if (userMessage) {
      prompt += `User said: "${userMessage}"\n\n`;
    }

    // Include tool outputs as context
    if (toolCalls.length > 0) {
      prompt += 'Tool outputs (use this data to compose response):\n';
      for (const call of toolCalls) {
        if (call.output.success && call.output.data) {
          prompt += `\n${call.toolName}:\n${JSON.stringify(call.output.data, null, 2)}\n`;
        } else if (call.output.error) {
          prompt += `\n${call.toolName} error: ${call.output.error}\n`;
        }
      }
    }

    // Include current preferences
    prompt += `\nCurrent trip preferences:\n${JSON.stringify(context.preferences, null, 2)}`;

    // Include edit target if editing
    if (context.editTarget) {
      prompt += `\n\nEdit target: ${JSON.stringify(context.editTarget, null, 2)}`;
    }

    prompt += '\n\nCompose a natural, conversational response.';

    return prompt;
  }

  /**
   * Optimize text for voice/TTS
   * - Remove markdown formatting
   * - Simplify punctuation
   * - Ensure natural pauses
   */
  private optimizeForVoice(text: string): string {
    return text
      .replace(/\*\*(.*?)\*\*/g, '$1') // Remove bold
      .replace(/\*(.*?)\*/g, '$1') // Remove italic
      .replace(/\[(.*?)\]\(.*?\)/g, '$1') // Remove links, keep text
      .replace(/\n{3,}/g, '\n\n') // Max 2 newlines
      .trim();
  }

  /**
   * Fallback response when LLM fails
   */
  private fallbackResponse(
    context: ConversationContext,
    toolCalls: ToolCallResult[]
  ): ComposedResponse {
    let text = '';

    switch (context.state) {
      case 'INIT':
        text = "I'd be happy to help you plan your trip! Where would you like to go?";
        break;

      case 'COLLECTING_PREFS':
        text = 'Could you tell me more about your travel preferences?';
        break;

      case 'CONFIRMING':
        text = 'Please confirm if these details are correct.';
        break;

      case 'PLANNED':
        if (toolCalls.length > 0) {
          text = "I've generated your itinerary. You can view it and make edits if needed.";
        } else {
          text = 'Your itinerary is ready.';
        }
        break;

      case 'EDITING':
        text = "I've updated your itinerary based on your request.";
        break;

      case 'EXPLAINING':
        text = 'Let me explain that for you.';
        break;

      default:
        text = 'How can I help you with your trip?';
    }

    return {
      text,
      state: context.state,
      metadata: {
        tripId: context.tripId,
      },
    };
  }

  /**
   * Compose explanation response with RAG citations
   * Used specifically for EXPLAINING state
   * 
   * Now uses RAG service for retrieval
   */
  async composeExplanation(
    context: ConversationContext,
    ragData: { content: string; citations: Citation[] },
    question: string
  ): Promise<ComposedResponse> {
    const systemPrompt = `You are explaining travel planning decisions.
Use the provided RAG data to give grounded explanations.
Mention sources naturally when relevant.
Keep explanations concise for voice.`;

    const userPrompt = `User asked: "${question}"

RAG data:
${ragData.content}

Citations:
${JSON.stringify(ragData.citations, null, 2)}

Compose a clear explanation that incorporates this information.`;

    try {
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4-turbo-preview',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt },
        ],
        temperature: 0.6,
      });

      const text = response.choices[0]?.message?.content || 'I cannot provide an explanation at this time.';

      return {
        text: this.optimizeForVoice(text),
        citations: ragData.citations,
        state: context.state,
        metadata: {
          tripId: context.tripId,
        },
      };
    } catch (error) {
      console.error('Explanation composition error:', error);
      return {
        text: 'I apologize, I encountered an error while preparing the explanation.',
        citations: ragData.citations,
        state: context.state,
        metadata: {
          tripId: context.tripId,
        },
      };
    }
  }
}

