/**
 * ResponseComposer
 * 
 * Composes natural language responses from tool outputs and context.
 * 
 * Responsibilities:
 * - Generate user-facing responses using LLM
 * - Incorporate tool outputs into responses
 * - Include citations from RAG sources
 * - Maintain conversational tone
 * 
 * Rules:
 * - LLM is used HERE for response generation (not tool calling)
 * - Responses must include citations when available
 * - Responses should be concise for voice (TTS)
 * - Citations appear in UI, not in voice response
 */

import OpenAI from 'openai';
import {
  ConversationContext,
  ToolCallResult,
  ComposedResponse,
  Citation,
} from './types';
import { config } from '../config/env';
import { retrieveRAGData } from '../rag/rag-service';

export class ResponseComposer {
  private openai: OpenAI;

  constructor() {
    if (!config.openai?.apiKey) {
      throw new Error('OpenAI API key is required for ResponseComposer');
    }
    this.openai = new OpenAI({ apiKey: config.openai.apiKey });
  }

  /**
   * Compose response based on context and tool results
   * 
   * This is where LLM generates the actual user-facing text.
   * Tool outputs are provided as context, not generated by LLM.
   * 
   * RAG is used for city guidance (safety, etiquette, areas to visit).
   */
  async composeResponse(
    context: ConversationContext,
    toolCalls: ToolCallResult[],
    userMessage?: string
  ): Promise<ComposedResponse> {
    // Collect all citations from tool outputs
    const citations: Citation[] = [];
    for (const call of toolCalls) {
      if (call.output.citations && Array.isArray(call.output.citations)) {
        citations.push(...call.output.citations);
      }
    }
    
    // Also collect citations from POI search results if available
    const poiSearchCall = toolCalls.find(call => call.toolName === 'poi_search');
    if (poiSearchCall && poiSearchCall.output.success && poiSearchCall.output.data) {
      const searchOutput = poiSearchCall.output.data;
      // POI search returns { pois: POI[], city: string, ... }
      if (searchOutput.pois && Array.isArray(searchOutput.pois)) {
        // Add OSM citations for POIs (limit to avoid too many citations)
        searchOutput.pois.slice(0, 10).forEach((poi: any) => {
          if (poi.osmId) {
            citations.push({
              source: 'OpenStreetMap',
              url: `https://www.openstreetmap.org/node/${poi.osmId}`,
              excerpt: `${poi.name} - ${poi.category}`,
              confidence: 1.0,
            });
          }
        });
      }
    }

    // Retrieve RAG data for city guidance (safety, etiquette, areas to visit)
    let ragData: { content: string; citations: Citation[] } | null = null;
    if (context.preferences.city) {
      try {
        // Retrieve RAG data for practical city guidance
        const ragResult = await retrieveRAGData(
          `Practical travel information for ${context.preferences.city} including safety, etiquette, areas to visit, and local tips`,
          context.preferences.city,
          undefined // No specific section - get general city guidance
        );

        if (ragResult.hasData && ragResult.chunks.length > 0) {
          ragData = {
            content: ragResult.chunks.map(c => c.text).join('\n\n'),
            citations: ragResult.citations || [],
          };
          // Add RAG citations to the citations array
          if (ragData.citations.length > 0) {
            citations.push(...ragData.citations);
          }
        }
      } catch (error) {
        const errorMessage = error instanceof Error ? error.message : String(error);
        console.warn('RAG data retrieval failed (continuing without RAG):', errorMessage);
        // Continue without RAG data - don't fail the response
        // The application will work without RAG, just without enhanced city guidance
      }
    }

    // Build prompt based on state
    const systemPrompt = this.buildSystemPrompt(context);
    const userPrompt = this.buildUserPrompt(context, toolCalls, userMessage, ragData);

    try {
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4-turbo-preview',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt },
        ],
        temperature: 0.7, // Higher temperature for more natural responses
      });

      const text = response.choices[0]?.message?.content || 'I apologize, I encountered an error.';

      // Log citations for debugging
      console.log('ResponseComposer citations:', {
        total: citations.length,
        sources: citations.map(c => c.source),
        ragCitations: ragData?.citations?.length || 0,
      });

      return {
        text: this.optimizeForVoice(text),
        citations: citations.length > 0 ? citations : undefined,
        state: context.state,
        metadata: {
          tripId: context.tripId,
        },
      };
    } catch (error) {
      console.error('Response composition error:', error);
      return this.fallbackResponse(context, toolCalls);
    }
  }

  /**
   * Build system prompt for response generation
   */
  private buildSystemPrompt(context: ConversationContext): string {
    const basePrompt = `You are a helpful voice-first travel planning assistant.
Your responses will be converted to speech, so keep them:
- Concise and natural
- Conversational and friendly
- Clear and easy to understand when spoken

Current conversation state: ${context.state}

Rules:
- Never mention that you're using tools or databases
- If data is missing, say so explicitly (e.g., "I don't have information about...")
- Be specific about recommendations
- For explanations, cite sources naturally
- All factual tips about safety, etiquette, areas to visit, and local guidance MUST be grounded in RAG data
- No hallucinated claims - if RAG data is missing, explicitly state the limitation`;

    switch (context.state) {
      case 'INIT':
        return `${basePrompt}
You're starting a new conversation. Greet the user naturally.
IMPORTANT: Do NOT mention any trip details, dates, or cities unless the user explicitly brings them up.
If the user is just greeting you (e.g., "Hi, how are you?"), respond with a friendly greeting and wait for them to mention their travel plans.`;

      case 'COLLECTING_PREFS':
        return `${basePrompt}
You're collecting trip preferences. Ask clarifying questions naturally (maximum 6 questions total).
IMPORTANT: Do NOT generate the itinerary yet. Only ask questions to collect missing information.
Collected so far: ${context.collectedFields.join(', ') || 'none'}
Still need: ${context.missingFields.join(', ') || 'none'}
Ask ONE question at a time. Be conversational and natural.`;

      case 'CONFIRMING':
        return `${basePrompt}
You're confirming the trip details before generating the itinerary.
IMPORTANT: You MUST summarize what you understand and explicitly ask for confirmation before generating the itinerary.
Do NOT generate the itinerary until the user confirms (says "yes", "correct", "that's right", "go ahead", etc.).
Format your response as:
1. Summarize the trip details you've collected (city, duration, start date, interests, pace)
2. Ask: "Does this sound right? Should I go ahead and create your itinerary?"
Wait for user confirmation before proceeding.`;

      case 'PLANNED':
        return `${basePrompt}
An itinerary has been generated. You can:
- Present the itinerary
- Answer questions about it
- Help with edits
- Provide city guidance (safety, etiquette, areas to visit) using RAG data
- All factual information must be cited`;

      case 'EDITING':
        return `${basePrompt}
The user is editing the itinerary. Acknowledge the edit and confirm what changed.`;

      case 'EXPLAINING':
        return `${basePrompt}
The user is asking for explanations. Provide clear, grounded explanations.
If you cite sources, mention them naturally (e.g., "According to Wikivoyage...").`;

      default:
        return basePrompt;
    }
  }

  /**
   * Build user prompt with context and tool outputs
   */
  private buildUserPrompt(
    context: ConversationContext,
    toolCalls: ToolCallResult[],
    userMessage?: string,
    ragData?: { content: string; citations: Citation[] } | null
  ): string {
    let prompt = '';

    if (userMessage) {
      prompt += `User said: "${userMessage}"\n\n`;
    }

    // Include RAG data for city guidance (safety, etiquette, areas to visit)
    if (ragData && ragData.content) {
      prompt += `City Travel Guide Information (from RAG - use this for practical guidance, safety tips, etiquette, and areas to visit):\n${ragData.content}\n\n`;
      prompt += `IMPORTANT: All factual information about safety, etiquette, areas to visit, and local tips MUST be based on the RAG data above. Do not make up facts. If the RAG data doesn't cover something, explicitly say "I don't have detailed information about this in my knowledge base."\n\n`;
    }

    // Include tool outputs as context
    if (toolCalls.length > 0) {
      prompt += 'Tool outputs (use this data to compose response):\n';
      for (const call of toolCalls) {
        if (call.output.success && call.output.data) {
          prompt += `\n${call.toolName}:\n${JSON.stringify(call.output.data, null, 2)}\n`;
        } else if (call.output.error) {
          prompt += `\n${call.toolName} error: ${call.output.error}\n`;
        }
      }
    }

    // Include current preferences ONLY if they're actually set and relevant
    const relevantPreferences: Record<string, any> = {};
    if (context.preferences.city) relevantPreferences.city = context.preferences.city;
    if (context.preferences.duration) relevantPreferences.duration = context.preferences.duration;
    if (context.preferences.startDate && context.state !== 'INIT') {
      // Only include startDate if we're actually planning (not just greeting)
      relevantPreferences.startDate = context.preferences.startDate;
    }
    if (context.preferences.interests && context.preferences.interests.length > 0) {
      relevantPreferences.interests = context.preferences.interests;
    }
    if (context.preferences.pace) relevantPreferences.pace = context.preferences.pace;

    // Only include preferences if there are any relevant ones
    if (Object.keys(relevantPreferences).length > 0) {
      prompt += `\nCurrent trip preferences:\n${JSON.stringify(relevantPreferences, null, 2)}`;
    } else {
      // If no preferences set, explicitly tell LLM not to mention trip details
      prompt += `\n\nIMPORTANT: The user has NOT provided any trip details yet. Do NOT mention dates, cities, or trip planning unless the user explicitly asks about it.`;
    }

    // Include edit target if editing
    if (context.editTarget) {
      prompt += `\n\nEdit target: ${JSON.stringify(context.editTarget, null, 2)}`;
    }

    prompt += '\n\nCompose a natural, conversational response.';

    return prompt;
  }

  /**
   * Optimize text for voice/TTS
   * - Remove markdown formatting
   * - Simplify punctuation
   * - Ensure natural pauses
   */
  private optimizeForVoice(text: string): string {
    return text
      .replace(/\*\*(.*?)\*\*/g, '$1') // Remove bold
      .replace(/\*(.*?)\*/g, '$1') // Remove italic
      .replace(/\[(.*?)\]\(.*?\)/g, '$1') // Remove links, keep text
      .replace(/\n{3,}/g, '\n\n') // Max 2 newlines
      .trim();
  }

  /**
   * Fallback response when LLM fails
   */
  private fallbackResponse(
    context: ConversationContext,
    toolCalls: ToolCallResult[]
  ): ComposedResponse {
    let text = '';

    switch (context.state) {
      case 'INIT':
        text = "I'd be happy to help you plan your trip! Where would you like to go?";
        break;

      case 'COLLECTING_PREFS':
        text = 'Could you tell me more about your travel preferences?';
        break;

      case 'CONFIRMING':
        text = 'Please confirm if these details are correct.';
        break;

      case 'PLANNED':
        if (toolCalls.length > 0) {
          text = "I've generated your itinerary. You can view it and make edits if needed.";
        } else {
          text = 'Your itinerary is ready.';
        }
        break;

      case 'EDITING':
        text = "I've updated your itinerary based on your request.";
        break;

      case 'EXPLAINING':
        text = 'Let me explain that for you.';
        break;

      default:
        text = 'How can I help you with your trip?';
    }

    return {
      text,
      state: context.state,
      metadata: {
        tripId: context.tripId,
      },
    };
  }

  /**
   * Compose explanation response with RAG citations
   * Used specifically for EXPLAINING state
   * 
   * Now uses RAG service for retrieval
   */
  async composeExplanation(
    context: ConversationContext,
    ragData: { content: string; citations: Citation[] },
    question: string
  ): Promise<ComposedResponse> {
    const systemPrompt = `You are explaining travel planning decisions.
Use the provided RAG data to give grounded explanations.
Mention sources naturally when relevant.
Keep explanations concise for voice.`;

    const userPrompt = `User asked: "${question}"

RAG data:
${ragData.content}

Citations:
${JSON.stringify(ragData.citations, null, 2)}

Compose a clear explanation that incorporates this information.`;

    try {
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4-turbo-preview',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt },
        ],
        temperature: 0.6,
      });

      const text = response.choices[0]?.message?.content || 'I cannot provide an explanation at this time.';

      return {
        text: this.optimizeForVoice(text),
        citations: ragData.citations,
        state: context.state,
        metadata: {
          tripId: context.tripId,
        },
      };
    } catch (error) {
      console.error('Explanation composition error:', error);
      return {
        text: 'I apologize, I encountered an error while preparing the explanation.',
        citations: ragData.citations,
        state: context.state,
        metadata: {
          tripId: context.tripId,
        },
      };
    }
  }
}

